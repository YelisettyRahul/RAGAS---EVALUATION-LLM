{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34fc60c7-f7ef-4881-8197-0dfac731ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples_text(filename=\"samples.json\"):\n",
    "    \"\"\"Loads the samples from a JSON file.\"\"\"\n",
    "    with open(filename, \"r\") as f:  # Open in read mode (\"r\")\n",
    "        data = json.load(f)\n",
    "    return [SingleTurnSample(**item) for item in data]  # Recreate SingleTurnSample objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b119e6f0-0256-43da-a806-6b95a084577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_samples = load_samples_text(\"samples.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac72bd9-e630-420b-a3c7-5a29cae64a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c44150c-5f95-4880-ae6d-08d80e3ccb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import sentence_transformers\n",
    "from ragas import SingleTurnSample, EvaluationDataset, evaluate\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from ragas.metrics import ResponseRelevancy, FactualCorrectness, LLMContextRecall, LLMContextPrecisionWithoutReference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00f7456-47c3-4824-8191-492db286e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e83a7a8-5792-402d-9973-cacdb858e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextPrecisionWithoutReference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1002f9f-2a0a-4b25-9c38-b085af038664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YELISETTY RAHUL\\AppData\\Local\\Temp\\ipykernel_12196\\2443225623.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"allenai/scibert_scivocab_uncased\")\n",
      "No sentence-transformers model found with name allenai/scibert_scivocab_uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baef5a9d08bb4ad69f00774574dd1606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YELISETTY RAHUL\\Music\\aiml\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\YELISETTY RAHUL\\.cache\\huggingface\\hub\\models--allenai--scibert_scivocab_uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faee9c39ceb64094ac24e3fbed7078a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f0c74492ca4f659b08f020954943ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccadffc0a6484fa9b88d03e30780ac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/228k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"allenai/scibert_scivocab_uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b9e646-50ce-4857-9309-3b0f57abfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_final = LangchainEmbeddingsWrapper(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80e5d135-06b1-4b2a-a776-e94f159b68ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name allenai/scibert_scivocab_uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings\n",
    "embeddings = LangchainEmbeddingsWrapper(\n",
    "    HuggingFaceEmbeddings(model_name=\"allenai/scibert_scivocab_uncased\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e34aeb9d-f9f2-4aca-8b8f-905081facf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LangchainEmbeddingsWrapper(embeddings=HuggingFaceEmbeddings(...))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "079f91b4-fee3-46cc-b7fa-fc8ee88505fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API tokens\n",
    "os.environ[\"RAGAS_APP_TOKEN\"] = \"apt.49b2-ab9d532bcd45-e6f1-9ea8-f4708472-b3f55\"\n",
    "os.environ[\"GEMINI_API_KEY\"] = 'AIzaSyBc0lVvh2Aa027ccp3wa9P96NvuzMYrfdc'\n",
    "api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', temperature=0, api_key=api_key)\n",
    "llm_instance = LangchainLLMWrapper(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af9ef1ab-43eb-43f2-990d-d1b0d4f657e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sample 1/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8214568f273f4ccdab35c79feef0facc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 1/90 | Result: {'answer_relevancy': 0.9600, 'factual_correctness(mode=f1)': 0.8000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 2/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee44988272c41be8fba562a7a3be672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 6\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 6\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 2/90 | Result: {'answer_relevancy': 0.9811, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 3/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fe1a7636e045768e6a2163ecfa3c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 3/90 | Result: {'answer_relevancy': 0.8515, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 4/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f4e54eb8934c748a60858c0ced74ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 4/90 | Result: {'answer_relevancy': 0.8262, 'factual_correctness(mode=f1)': 0.4000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 5/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749faf17200f425c93e2d95ad256d398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 5/90 | Result: {'answer_relevancy': 0.8485, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 6/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da85ff766b64942b316f75a99dd1fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 6/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.1800, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 7/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8556c14ec743fab572f2b832280c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 7/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 8/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34481a469ba94a2f8a866882788c4638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 8/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2500, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 9/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56be3dbdc6874df2b331d678e4a61635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 9/90 | Result: {'answer_relevancy': 0.8388, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 10/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043f34ecf2c44dfbac01ecd087bbd26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 10/90 | Result: {'answer_relevancy': 0.9507, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 11/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23622848bd6c4ca19c5722f3e4d20581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 11/90 | Result: {'answer_relevancy': 0.8336, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 12/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568ae0c499e44892979766b2b6d74321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 12/90 | Result: {'answer_relevancy': 0.7843, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 13/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a018dcca8ebf44f0b9a8c52adaf013ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 13/90 | Result: {'answer_relevancy': 0.8141, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 14/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869065fbb29d4dbe8459c17fe639d2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 14/90 | Result: {'answer_relevancy': 0.8026, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 15/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22215fecc1e84fce8dc723ac602811f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 15/90 | Result: {'answer_relevancy': 0.7546, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 16/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71a913369474066a190a74f9791358b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 16/90 | Result: {'answer_relevancy': 0.7770, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 17/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764ad6714c4c4ee1995ca4f03a738ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 6\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 17/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 18/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beb5e9377e34e82a4cd31fded30e57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 18/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 19/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207eb1637f15445d945dc75f46841c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 19/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 20/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e9e5dd76df4deeb27ca79f8ceea13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 20/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 21/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1207204935643bf82cec2f323a068d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 21/90 | Result: {'answer_relevancy': 0.8737, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 22/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6046ddb5adcf4d9cadd066b756d0ace8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 22/90 | Result: {'answer_relevancy': 0.7283, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 23/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af27fc8a5ea4a1782b2fa587b5b338b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 23/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 24/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00627cc234a948fe9ed51652dc0119d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 24/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2900, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 25/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af4d17e99964152a7ca0329ca0616c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 25/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 26/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516c414dd77242f996dbc43d642bc0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 26/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3600, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 27/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2205feadee6846a48f675ce1c28d9e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 11\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 11\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 27/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 28/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0c3775002a482186c38af8c0bb84de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 28/90 | Result: {'answer_relevancy': 0.8829, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 29/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c04b269c28496b92e01ce0b410b916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 29/90 | Result: {'answer_relevancy': 0.8512, 'factual_correctness(mode=f1)': 0.7500, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 30/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbb580c62b74ca9860a273c1eb3155b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 30/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 31/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69a7ffd4f484e6ca40ac3ed98ee334b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 31/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 32/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e739abd580854154b882de6d65d5cb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 32/90 | Result: {'answer_relevancy': 0.9232, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 33/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31414553b6e47519ed34a8829a6778c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 33/90 | Result: {'answer_relevancy': 0.7146, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 34/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c420dfdff674c4ead95d91a310904db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 34/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 35/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14aa9fb05ad4edd80f22ea135a3de67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 35/90 | Result: {'answer_relevancy': 0.9854, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 36/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784ed6729a6f41fc8261c1783148e662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 36/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 37/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02b161c0cda4cd398eca56766da4ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 37/90 | Result: {'answer_relevancy': 0.9851, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 38/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2def8f6db84d639d6208ff697d51d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 38/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 39/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf2720a10b0441389fda572c9aecdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 39/90 | Result: {'answer_relevancy': 0.9884, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 40/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7523412de6146d0b94afe799e6baa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 40/90 | Result: {'answer_relevancy': 0.9900, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 41/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5ff9d5c20c4fccbc6cf680405dae5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 41/90 | Result: {'answer_relevancy': 0.8816, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 42/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffa810f5f1c4de79692f3cbf07ab96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 42/90 | Result: {'answer_relevancy': 0.7580, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 43/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577bef0f9de244a990afecb7804e5841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 43/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 44/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0147b76210794da0af06a14fd9128371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 44/90 | Result: {'answer_relevancy': 0.8549, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 45/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b23714d02649469ea32d9de140a0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 45/90 | Result: {'answer_relevancy': 0.8260, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 46/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88a183d2b0c47f6ad98a9eef4c7bbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 46/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 47/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a0aa56499442308d595d6830c86e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 47/90 | Result: {'answer_relevancy': 0.8443, 'factual_correctness(mode=f1)': 0.4400, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 48/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6681957bfe45848007f8e95b96b5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 48/90 | Result: {'answer_relevancy': 0.8876, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 49/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35dd318f1d9040f489abd60e9b69c36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 49/90 | Result: {'answer_relevancy': 0.8925, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 50/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7a8eb4e9b04c0891f5e69f9d265ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 50/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 51/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63451bcb9e424959908986e5f578abc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 51/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 52/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e86e97c66224a5ca4f9dc692f07c940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 52/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 53/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2568e7c16b884e1a9cd43856391c1884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 53/90 | Result: {'answer_relevancy': 0.9337, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 54/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73442a0f030e4b04afe35317e2b6d30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 54/90 | Result: {'answer_relevancy': 0.8812, 'factual_correctness(mode=f1)': 0.8000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 55/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bf6b2675fb4bdea386c059aa48b39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 55/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 56/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d2f9706986442585ee9473f1fd362a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 56/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 57/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3e8ddca1f4405caba9325f3e86025b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 57/90 | Result: {'answer_relevancy': 0.9070, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 58/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380d140d45594d81858b424898e86166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 58/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3100, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 59/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c58cffbbc64c249da959b649864779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 59/90 | Result: {'answer_relevancy': 0.8008, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 60/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249721bf694249d9a46d177e4e50613a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 60/90 | Result: {'answer_relevancy': 0.7590, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 61/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6848c4f986594ea19147aeebafb8459e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 61/90 | Result: {'answer_relevancy': 0.9907, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 62/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86601b6d96748a58b415eea35aa20e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 62/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3600, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 63/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9e0fa06e664d729b271f59523a25ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 63/90 | Result: {'answer_relevancy': 0.8006, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 64/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbdcf8102a245f5ac2c8512ea62ab7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 64/90 | Result: {'answer_relevancy': 0.8200, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 65/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d36f0760344487986ecccee871de76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 65/90 | Result: {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 66/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c8a034e00c4d86aa5c4f8134be4b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 66/90 | Result: {'answer_relevancy': 0.8286, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 67/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e17e237445f435f9d4188823ddbcacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 67/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 68/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865b79c93aa046eeab12abc23528d873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 68/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 69/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a8bd5bd5814833b12118a406dde8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 69/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 70/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b199276122134c4f8a4f238e46506ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 70/90 | Result: {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 71/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c502fdf96ce4a4d81a77fad8953bafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 71/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 72/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1df9de35eb44ac79bec4eb1261abf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 72/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.1700, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 73/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c331914a96104962b2089cf0ce37b43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 73/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.4000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 74/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8535b17fea64a5aaddf9feb5439ac71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 74/90 | Result: {'answer_relevancy': 0.9026, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 75/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a8b7ffff0f4ddbb4498f6e46620e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 75/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 76/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2d3809706a41a1ad73f7328a3192dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 76/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 77/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a47a0f4e0a422dacabcfd516e645ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 77/90 | Result: {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 78/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c014eec1cc43f986465018b2f38561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 78/90 | Result: {'answer_relevancy': 0.9731, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 79/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3d9b927fc1402287b438415ba4dd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 79/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 80/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005534be92114b7ca3f1aefa1a30a5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 80/90 | Result: {'answer_relevancy': 0.8720, 'factual_correctness(mode=f1)': 0.6000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 81/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f703fca13f94ff8a3cc76e83ef58b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 81/90 | Result: {'answer_relevancy': 0.8062, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 82/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7fc5f01e0b45fb805d6ab97a8db7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 82/90 | Result: {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 83/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9beb19344c15435fa0946a568a37068d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 83/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 84/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5abcae8107249f4979f0411454193a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 84/90 | Result: {'answer_relevancy': 0.9251, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 85/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d638eddba81546339e5eb81b5d1f4caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 85/90 | Result: {'answer_relevancy': 0.9899, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 86/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37dd36f2d5d4414b8a2fb42117207199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 86/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 87/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671df209cfd940639c08286015918ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 87/90 | Result: {'answer_relevancy': 0.8581, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 88/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6197f6a3ec4328b2447b8ad5b95095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 88/90 | Result: {'answer_relevancy': 0.8192, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 89/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739575ea29624c0fbbf3ada4bf4a8369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 89/90 | Result: {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "\n",
      "Processing sample 90/90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee69bb5c1874f8ab8c51bbfbbeed013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed 90/90 | Result: {'answer_relevancy': 0.9173, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
      "⏳ Waiting 45 seconds before processing the next sample...\n",
      "\n",
      "🚀 Uploading all results at once...\n",
      "✅ All results uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Create an empty list to store results\n",
    "all_results = []\n",
    "\n",
    "# Define metrics\n",
    "metrics = [\n",
    "    ResponseRelevancy(llm=llm_instance),\n",
    "    FactualCorrectness(llm=llm_instance),\n",
    "    LLMContextPrecisionWithoutReference(llm=llm_instance),\n",
    "    LLMContextRecall(llm=llm_instance)\n",
    "]\n",
    "\n",
    "# Initi\n",
    "\n",
    "# Define delay time for each iteration\n",
    "DEFAULT_DELAY = 45 # Wait 16s before the next loop iteration\n",
    "RATE_LIMIT_DELAY = 60  # If rate limited, wait 60s\n",
    "\n",
    "# Loop through each sample and evaluate individually\n",
    "for i, sample in enumerate(loaded_samples):\n",
    "    print(f\"\\nProcessing sample {i + 1}/{len(loaded_samples)}...\")\n",
    "\n",
    "    eval_dataset = EvaluationDataset([sample])\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Evaluate the sample\n",
    "            result = evaluate(dataset=eval_dataset, embeddings=embeddings_final, metrics=metrics, llm=llm_instance)\n",
    "            all_results.append(result)  # Store result\n",
    "            print(f\"✅ Completed {i + 1}/{len(loaded_samples)} | Result: {result}\")\n",
    "\n",
    "            break  # Exit retry loop on success\n",
    "\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):  # Check if the error is rate limit exceeded\n",
    "                print(f\"⚠️ Rate limit exceeded! Retrying in {RATE_LIMIT_DELAY} seconds...\")\n",
    "                time.sleep(RATE_LIMIT_DELAY)  # Wait before retrying\n",
    "            else:\n",
    "                print(f\"❌ Error processing sample {i + 1}: {e}\")\n",
    "                break  # Exit loop for non-rate-limit errors\n",
    "\n",
    "    # Ensure the next loop iteration waits 16 seconds\n",
    "    print(f\"⏳ Waiting {DEFAULT_DELAY} seconds before processing the next sample...\\n\")\n",
    "    time.sleep(DEFAULT_DELAY)\n",
    "\n",
    "# Upload all results at once\n",
    "if all_results:\n",
    "    print(\"🚀 Uploading all results at once...\")\n",
    "    final_dataset = EvaluationDataset(all_results)\n",
    "    # final_dataset.upload()  # Uncomment if the upload method exists\n",
    "    print(\"✅ All results uploaded successfully!\")\n",
    "else:\n",
    "    print(\"⚠️ No results to upload.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ce2dffa-e726-4e73-a754-b9c822e5941f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer_relevancy': 0.9600, 'factual_correctness(mode=f1)': 0.8000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.9811, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8515, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8262, 'factual_correctness(mode=f1)': 0.4000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8485, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.1800, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2500, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8388, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.9507, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8336, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.7843, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8141, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8026, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.7546, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.7770, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8737, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.7283, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2900, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3600, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8829, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8512, 'factual_correctness(mode=f1)': 0.7500, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.9232, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.7146, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.9854, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.9851, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.9884, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.9900, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8816, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.7580, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8549, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8260, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8443, 'factual_correctness(mode=f1)': 0.4400, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8876, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8925, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.9337, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8812, 'factual_correctness(mode=f1)': 0.8000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.9070, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3100, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8008, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.7590, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.9907, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3600, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8006, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8200, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8286, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.1700, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.4000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.9026, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.9731, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8720, 'factual_correctness(mode=f1)': 0.6000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8062, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.9251, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.9899, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.8581, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
       " {'answer_relevancy': 0.8192, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
       " {'answer_relevancy': 0.9173, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18ac80a9-fd0f-4292-9f35-3ce15a09198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56241250-1f76-432f-87e4-fd5241878ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.5075088888888889,\n",
       " 'factual_correctness(mode=f1)': 0.1951111111111111,\n",
       " 'llm_context_precision_without_reference': 0.5259177777777778,\n",
       " 'context_recall': 0.4444444444444444}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting numerical values from the given data\n",
    "\n",
    "data = [\n",
    "    {'answer_relevancy': 0.9600, 'factual_correctness(mode=f1)': 0.8000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.9811, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8515, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8262, 'factual_correctness(mode=f1)': 0.4000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8485, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.1800, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2500, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8388, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.9507, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8336, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.7843, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8141, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8026, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.7546, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.7770, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8737, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.7283, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2900, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3600, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8829, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8512, 'factual_correctness(mode=f1)': 0.7500, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.9232, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.7146, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.9854, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.9851, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.9884, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.9900, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8816, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.7580, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8549, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8260, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8443, 'factual_correctness(mode=f1)': 0.4400, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8876, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8925, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.9337, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8812, 'factual_correctness(mode=f1)': 0.8000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.9070, 'factual_correctness(mode=f1)': 1.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3100, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8008, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.7590, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.9907, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3600, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8006, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8200, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5833, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8286, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.1700, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.4000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.9026, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.5000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.5000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.9731, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8720, 'factual_correctness(mode=f1)': 0.6000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8062, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.8333, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 1.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.9251, 'factual_correctness(mode=f1)': 0.3300, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.9899, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 0.3333, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.6700, 'llm_context_precision_without_reference': 0.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.8581, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000},\n",
    " {'answer_relevancy': 0.8192, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.0000, 'factual_correctness(mode=f1)': 0.2200, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.0000},\n",
    " {'answer_relevancy': 0.9173, 'factual_correctness(mode=f1)': 0.0000, 'llm_context_precision_without_reference': 1.0000, 'context_recall': 1.0000}\n",
    "]\n",
    "\n",
    "# Calculating averages for each metric\n",
    "means = {key: sum(d[key] for d in data) / len(data) for key in data[0]}\n",
    "means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7d6e200-31c3-44ab-acb1-2d98d300fe48",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EvaluationResult' object has no attribute 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: precision, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy}\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#Example usage (assuming 'all_results' is a list of EvaluationResult objects)\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m averages \u001b[38;5;241m=\u001b[39m calculate_averages(all_results)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverages:\u001b[39m\u001b[38;5;124m\"\u001b[39m, averages)\n\u001b[0;32m     45\u001b[0m precision_accuracy \u001b[38;5;241m=\u001b[39m calculate_precision_accuracy(all_results)\n",
      "Cell \u001b[1;32mIn[39], line 10\u001b[0m, in \u001b[0;36mcalculate_averages\u001b[1;34m(results)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}  \u001b[38;5;66;03m# Return empty dictionary if results list is empty\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract the dictionary representation of the EvaluationResult objects\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m result_dicts \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39mdict() \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_dicts:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EvaluationResult' object has no attribute 'dict'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_averages(results):\n",
    "    \"\"\"Calculates the average of each metric from a list of EvaluationResult objects.\"\"\"\n",
    "\n",
    "    if not results:\n",
    "        return {}  # Return empty dictionary if results list is empty\n",
    "\n",
    "    # Extract the dictionary representation of the EvaluationResult objects\n",
    "    result_dicts = [result.dict() for result in results]\n",
    "\n",
    "    if not result_dicts:\n",
    "        return {}\n",
    "\n",
    "    metrics = result_dicts[0].keys()  # Get all metric names from the first result\n",
    "    averages = {}\n",
    "\n",
    "    for metric in metrics:\n",
    "        values = [result[metric] for result in result_dicts]\n",
    "        averages[metric] = np.mean(values)\n",
    "\n",
    "    return averages\n",
    "\n",
    "def calculate_precision_accuracy(all_results):\n",
    "    \"\"\"Calculates precision and accuracy based on factual_correctness.\"\"\"\n",
    "\n",
    "    if not results:\n",
    "        return {}\n",
    "\n",
    "    # Extract the dictionary representation of the EvaluationResult objects\n",
    "    result_dicts = [result.dict() for result in results]\n",
    "\n",
    "    factual_correctness_values = [result['factual_correctness(mode=f1)'] for result in result_dicts]\n",
    "    precision = np.mean(factual_correctness_values)\n",
    "\n",
    "    # Assuming accuracy is the same as precision for this example\n",
    "    accuracy = precision\n",
    "\n",
    "    return {'precision': precision, 'accuracy': accuracy}\n",
    "\n",
    "#Example usage (assuming 'all_results' is a list of EvaluationResult objects)\n",
    "averages = calculate_averages(all_results)\n",
    "print(\"Averages:\", averages)\n",
    "\n",
    "precision_accuracy = calculate_precision_accuracy(all_results)\n",
    "print(\"Precision and Accuracy:\", precision_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e210f5-1e5f-4139-be59-bfcc02578a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
